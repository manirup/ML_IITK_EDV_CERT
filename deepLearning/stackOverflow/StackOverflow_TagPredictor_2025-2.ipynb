{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d339d4d1",
   "metadata": {},
   "source": [
    "# Stack Overflow Tag Predictor\n",
    "Predict top 10 tags from Stack Overflow questions using LSTM.\n",
    "\n",
    "Might try transformers or GRU later — this is a basic prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (because dataset is big and already in Drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d477d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping data... already uploaded to Drive manually\n",
    "import zipfile\n",
    "zip_path = '/content/drive/MyDrive/stacksample.zip'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/stacksample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main files — skipping Answers.csv for now\n",
    "import pandas as pd\n",
    "questions = pd.read_csv('/content/stacksample/Questions.csv', encoding='latin1')\n",
    "tags = pd.read_csv('/content/stacksample/Tags.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's limit to the top 10 most frequent tags\n",
    "# Might expand this later once it's working well\n",
    "top_tags = tags['Tag'].value_counts().nlargest(10).index.tolist()\n",
    "tags = tags[tags['Tag'].isin(top_tags)]\n",
    "print(\"Top tags selected:\", top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge questions with their tags\n",
    "questions_tags = questions.merge(tags, on='Id')\n",
    "questions_tags['Tag'] = questions_tags['Tag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd741553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group tags by question (so we can multi-label)\n",
    "tag_lists = questions_tags.groupby('Id')['Tag'].apply(list)\n",
    "\n",
    "# Keep the text part of the questions\n",
    "questions_text = questions.drop_duplicates(subset='Id').set_index('Id').loc[tag_lists.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c10aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text cleaning — may improve with more advanced preprocessing later\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub('<.*?>', '', str(text))  # remove HTML\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "questions_text['Text'] = (questions_text['Title'] + ' ' + questions_text['Body']).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tag lists into multi-hot vectors\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=top_tags)\n",
    "y = mlb.fit_transform(tag_lists)\n",
    "print(\"Label shape:\", y.shape)  # should be (num_samples, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(questions_text['Text'])\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(questions_text['Text'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=300)  # might try 500 later\n",
    "print(\"Padded sequence shape:\", X_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2abfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model — LSTM first\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=20000, output_dim=128, input_length=300))\n",
    "model.add(LSTM(64))  # could test GRU too\n",
    "# model.add(GRU(64))\n",
    "model.add(Dense(10, activation='sigmoid'))  # multi-label output\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b360668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it — 3 epochs just to test things quickly\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Drive — in case we want to load and fine-tune later\n",
    "model.save('/content/drive/MyDrive/tag_predictor_model_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bfc75",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Can add pretrained GloVe embeddings later\n",
    "- Might try transformers if this does well\n",
    "- Could integrate question score or answer count as features too\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
