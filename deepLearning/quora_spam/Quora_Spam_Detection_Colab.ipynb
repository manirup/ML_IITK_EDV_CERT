{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b576dff",
   "metadata": {},
   "source": [
    "# Quora Spam Detection - Deep Learning Project\n",
    "This notebook builds a spam detection model for Quora questions using GloVe embeddings and LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy scikit-learn keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be27c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c62a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.dropna(subset=['question_text'], inplace=True)\n",
    "df['question_text'] = df['question_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['question_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload GloVe file: glove.6B.100d.txt\n",
    "glove_path = 'glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(glove_path, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_dim = 100\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25769b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embedding_dim, embeddings_initializer=Constant(embedding_matrix),\n",
    "                    input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2974435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
